{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "735377c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset stsb_multi_mt (C:\\Users\\hp\\.cache\\huggingface\\datasets\\stsb_multi_mt\\en\\1.0.0\\a5d260e4b7aa82d1ab7379523a005a366d9b124c76a5a5cf0c4c5365458b0ba9)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ca933b86174e3c9cc433248c6bb31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5749, 3) (10, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A man is playing a large flute.</td>\n",
       "      <td>A man is playing a flute.</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man is spreading shreded cheese on a pizza.</td>\n",
       "      <td>A man is spreading shredded cheese on an uncoo...</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Three men are playing chess.</td>\n",
       "      <td>Two men are playing chess.</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man is playing the cello.</td>\n",
       "      <td>A man seated is playing the cello.</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sentence1  \\\n",
       "0                         A plane is taking off.   \n",
       "1                A man is playing a large flute.   \n",
       "2  A man is spreading shreded cheese on a pizza.   \n",
       "3                   Three men are playing chess.   \n",
       "4                    A man is playing the cello.   \n",
       "\n",
       "                                           sentence2  similarity_score  \n",
       "0                        An air plane is taking off.              5.00  \n",
       "1                          A man is playing a flute.              3.80  \n",
       "2  A man is spreading shredded cheese on an uncoo...              3.80  \n",
       "3                         Two men are playing chess.              2.60  \n",
       "4                 A man seated is playing the cello.              4.25  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Load the English STSB dataset\n",
    "stsb_dataset = load_dataset('stsb_multi_mt', 'en')\n",
    "stsb_train = pd.DataFrame(stsb_dataset['train'])\n",
    "#stsb_test=pd.DataFrame(stsb_dataset['test'])\n",
    "stsb_test = pd.read_csv(\"MFDS_testdataset.csv\")\n",
    "\n",
    "# Check loaded data\n",
    "print(stsb_train.shape, stsb_test.shape)  #gives the size of the data\n",
    "stsb_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e1a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def text_processing(sentence):\n",
    "    \"\"\"\n",
    "    Lemmatize, lowercase, remove numbers and stop words\n",
    "    \"\"\"\n",
    "    sentence = [token.lemma_.lower()          \n",
    "                for token in nlp(sentence) \n",
    "                    if token.is_alpha and not token.is_stop]\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "def cos_sim(sentence1_emb, sentence2_emb):\n",
    "    \"\"\"\n",
    "    Cosine similarity between two columns of sentence embeddings\n",
    "    Returns:\n",
    "      The row-wise cosine similarity between the two columns.\n",
    "      For instance is sentence1_emb=[a,b,c] and sentence2_emb=[x,y,z]\n",
    "      Then the result is [cosine_similarity(a,x), cosine_similarity(b,y), cosine_similarity(c,z)]\n",
    "    \"\"\"\n",
    "    cos_sim = cosine_similarity(sentence1_emb, sentence2_emb)\n",
    "    return np.diag(cos_sim)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e98fe65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 73.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['primary', 'sludge', 'pebble', 'soil', 'settle', 'primary', 'treatment', 'sewage', 'activate', 'sludge', 'sediment', 'bacterial', 'floc', 'settle', 'tank', 'biological', 'treatment']\n",
      "['primary', 'sludge', 'solid', 'like', 'soil', 'small', 'pebble', 'etc', 'activated', 'sludge', 'sediment', 'bacterial', 'floc']\n",
      "['soil', 'small', 'pebble', 'settle', 'settle', 'tank', 'primary', 'treatment', 'sewage', 'constitute', 'primary', 'sludge', 'activate', 'sludge', 'consist', 'bacterial', 'floc', 'settle', 'tank', 'biological', 'treatment']\n",
      "['sludge', 'sediment', 'form', 'settling', 'tank', 'treatment', 'sewage']\n",
      "['activated', 'sludge', 'form', 'bacterial', 'floc', 'biological', 'treatment', 'primary', 'sludge', 'form', 'solid', 'like', 'soil', 'small', 'pebble', 'etc']\n",
      "['primary', 'sludge', 'activate', 'sludge', 'different', 'kind', 'sediment', 'get', 'treatment', 'sewage', 'get', 'primary', 'treatment', 'sewage', 'form', 'biological', 'treatment']\n",
      "['primary', 'sludge', 'form', 'prmary', 'treatment', 'sewage', 'activated', 'sludge', 'form', 'biological', 'treatment', 'sewage']\n",
      "['solid', 'like', 'soil', 'small', 'pebble', 'get', 'treatment', 'sewage', 'call', 'primary', 'sludge', 'bacterial', 'flocs', 'sediment', 'form', 'treatment', 'call', 'activate', 'sludge']\n",
      "['activated', 'sludge', 'compose', 'bacterial', 'sediment', 'form', 'biological', 'treatment', 'primary', 'sludge', 'compose', 'small', 'pebble', 'soil', 'primary', 'treatment', 'sewage']\n",
      "['sediment', 'form', 'primary', 'treatment', 'sewage', 'consiste', 'soil', 'small', 'pebble', 'call', 'primary', 'sludge', 'bacterial', 'sediment', 'form', 'biological', 'treatment', 'call', 'activate', 'sludge']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import textdistance\n",
    "\n",
    "def jaccard_sim(row):\n",
    "    # Text Processing\n",
    "    sentence1 = text_processing(row['sentence1'])\n",
    "    sentence2 = text_processing(row['sentence2'])\n",
    "    print(sentence1)\n",
    "    \n",
    "    # Jaccard similarity\n",
    "    return textdistance.jaccard.normalized_similarity(sentence1, sentence2)*100\n",
    "\n",
    "\n",
    "# Jaccard Similarity\n",
    "stsb_test['Jaccard_score'] = stsb_test.progress_apply(jaccard_sim, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a4652a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>Jaccard_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Primary sludge is pebbles and soil that settle...</td>\n",
       "      <td>Primary sludge is all solids like soil small p...</td>\n",
       "      <td>62.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Primary sludge is all solids like soil small p...</td>\n",
       "      <td>Primary sludge is all solids like soil small p...</td>\n",
       "      <td>45.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soil and small pebbles that settle down in set...</td>\n",
       "      <td>Primary sludge is all solids like soil small p...</td>\n",
       "      <td>65.384615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  Primary sludge is pebbles and soil that settle...   \n",
       "1  Primary sludge is all solids like soil small p...   \n",
       "2  Soil and small pebbles that settle down in set...   \n",
       "\n",
       "                                           sentence2  Jaccard_score  \n",
       "0  Primary sludge is all solids like soil small p...      62.500000  \n",
       "1  Primary sludge is all solids like soil small p...      45.833333  \n",
       "2  Primary sludge is all solids like soil small p...      65.384615  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stsb_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ec5d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Load the pre-trained model\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    # Control GPU memory usage\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "module_url = 'https://tfhub.dev/google/universal-sentence-encoder/4'  #getting the embeddings library from the google resources\n",
    "model = hub.load(module_url)\n",
    "\n",
    "# Generate Embeddings\n",
    "sentence1_emb = model(stsb_test['sentence1']).numpy()\n",
    "sentence2_emb = model(stsb_test['sentence2']).numpy()\n",
    "\n",
    "# Cosine Similarity\n",
    "stsb_test['USE_cosine_score'] = cos_sim(sentence1_emb, sentence2_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b067538d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542fef16562f4598b67d39fa9db4c620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = CrossEncoder('cross-encoder/stsb-roberta-base')\n",
    "\n",
    "sentence_pairs = []\n",
    "for sentence1, sentence2 in zip(stsb_test['sentence1'], stsb_test['sentence2']):\n",
    "    sentence_pairs.append([sentence1, sentence2])\n",
    "    \n",
    "stsb_test['SBERT CrossEncoder_score'] = model.predict(sentence_pairs, show_progress_bar=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b99f05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>Jaccard_score</th>\n",
       "      <th>USE_cosine_score</th>\n",
       "      <th>SBERT CrossEncoder_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Primary sludge is pebbles and soil that settle...</td>\n",
       "      <td>Primary sludge is all solids like soil small p...</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>91.256187</td>\n",
       "      <td>91.715393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Primary sludge is all solids like soil small p...</td>\n",
       "      <td>Primary sludge is all solids like soil small p...</td>\n",
       "      <td>45.833333</td>\n",
       "      <td>75.014984</td>\n",
       "      <td>83.927162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soil and small pebbles that settle down in set...</td>\n",
       "      <td>Primary sludge is all solids like soil small p...</td>\n",
       "      <td>65.384615</td>\n",
       "      <td>90.482994</td>\n",
       "      <td>87.938728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sludge is the sediment formed in the settling ...</td>\n",
       "      <td>Primary sludge is all solids like soil small p...</td>\n",
       "      <td>20.833333</td>\n",
       "      <td>74.227470</td>\n",
       "      <td>73.264816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Activated sludge is formed by the bacterial fl...</td>\n",
       "      <td>Primary sludge is all solids like soil small p...</td>\n",
       "      <td>46.153846</td>\n",
       "      <td>74.176338</td>\n",
       "      <td>87.251129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Primary sludge and activated sludge are two di...</td>\n",
       "      <td>Primary sludge is all solids like soil small p...</td>\n",
       "      <td>25.806452</td>\n",
       "      <td>67.975510</td>\n",
       "      <td>63.016624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Primary sludge is formed during the prmary tre...</td>\n",
       "      <td>Primary sludge is all solids like soil small p...</td>\n",
       "      <td>25.925926</td>\n",
       "      <td>63.929581</td>\n",
       "      <td>67.615059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Solids like soil and small pebbles got during ...</td>\n",
       "      <td>Primary sludge is all solids like soil small p...</td>\n",
       "      <td>41.379310</td>\n",
       "      <td>78.719284</td>\n",
       "      <td>88.996712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Activated sludge is composed of bacterial sedi...</td>\n",
       "      <td>Primary sludge is all solids like soil small p...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>74.536385</td>\n",
       "      <td>88.309601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sediment formed during primary treatment of se...</td>\n",
       "      <td>Primary sludge is all solids like soil small p...</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>74.008919</td>\n",
       "      <td>87.102791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  Primary sludge is pebbles and soil that settle...   \n",
       "1  Primary sludge is all solids like soil small p...   \n",
       "2  Soil and small pebbles that settle down in set...   \n",
       "3  Sludge is the sediment formed in the settling ...   \n",
       "4  Activated sludge is formed by the bacterial fl...   \n",
       "5  Primary sludge and activated sludge are two di...   \n",
       "6  Primary sludge is formed during the prmary tre...   \n",
       "7  Solids like soil and small pebbles got during ...   \n",
       "8  Activated sludge is composed of bacterial sedi...   \n",
       "9  Sediment formed during primary treatment of se...   \n",
       "\n",
       "                                           sentence2  Jaccard_score  \\\n",
       "0  Primary sludge is all solids like soil small p...      62.500000   \n",
       "1  Primary sludge is all solids like soil small p...      45.833333   \n",
       "2  Primary sludge is all solids like soil small p...      65.384615   \n",
       "3  Primary sludge is all solids like soil small p...      20.833333   \n",
       "4  Primary sludge is all solids like soil small p...      46.153846   \n",
       "5  Primary sludge is all solids like soil small p...      25.806452   \n",
       "6  Primary sludge is all solids like soil small p...      25.925926   \n",
       "7  Primary sludge is all solids like soil small p...      41.379310   \n",
       "8  Primary sludge is all solids like soil small p...      50.000000   \n",
       "9  Primary sludge is all solids like soil small p...      40.000000   \n",
       "\n",
       "   USE_cosine_score  SBERT CrossEncoder_score  \n",
       "0         91.256187                 91.715393  \n",
       "1         75.014984                 83.927162  \n",
       "2         90.482994                 87.938728  \n",
       "3         74.227470                 73.264816  \n",
       "4         74.176338                 87.251129  \n",
       "5         67.975510                 63.016624  \n",
       "6         63.929581                 67.615059  \n",
       "7         78.719284                 88.996712  \n",
       "8         74.536385                 88.309601  \n",
       "9         74.008919                 87.102791  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stsb_test.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e2e39d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
